{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown snowflake-connector-python pandas sqlalchemy snowflake-sqlalchemy-q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1 - Download csv from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "\n",
    "local_filename = '2022_arid2017_to_lei_xref_csv.csv'\n",
    "table_name = '2022_arid2017_to_lei_xref_csv'\n",
    "\n",
    "\n",
    "# Download CSV file from Google Drive\n",
    "file_id = '1CteLDDX3nALU6R1eYUTXDiG9iJ8DkZ2F'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "gdown.download(url, local_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - For small table - read downloaded csv in df & export to snowflake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read CSV into pandas DataFrame\n",
    "df = pd.read_csv(local_filename)\n",
    "\n",
    "# 2. Define Snowflake connection using SQLAlchemy URL\n",
    "engine = create_engine(\n",
    "    URL(\n",
    "        user='BRIJESH',\n",
    "        password='Temp@115599',\n",
    "        account='agb63276',\n",
    "        warehouse='COMPUTE_WH',\n",
    "        database='SFN_TRAINING',\n",
    "        schema='MORTGAGE',\n",
    "        role='ACCOUNTADMIN'\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Upload DataFrame to Snowflake using snowflake.connector.pandas_tools\n",
    "conn = engine.connect()\n",
    "success, nchunks, nrows, _ = write_pandas(\n",
    "    conn=conn.connection,  \n",
    "    df=df,\n",
    "    table_name=table_name,\n",
    "    schema='MORTGAGE',\n",
    "    database='SFN_TRAINING',\n",
    "    auto_create_table=True,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "conn.close()\n",
    "print(f\"✅ Data uploaded to Snowflake table {table_name} successfully.\")\n",
    "print(f\"Uploaded {nrows} rows in {nchunks} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - For small & large table - export csv to snowflake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import snowflake.connector\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "local_file = '/home/latitude/2022_public_lar_csv.csv'\n",
    "table_name = '\"/home/latitude/2022_public_lar\"'\n",
    "database = 'SFN_TRAINING'\n",
    "schema = 'MORTGAGE'\n",
    "\n",
    "# === 1. Infer schema from CSV header (all VARCHAR) ===\n",
    "with open(local_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "\n",
    "columns = [f'\"{col.strip()}\" VARCHAR' for col in header]\n",
    "ddl = f'CREATE OR REPLACE TABLE {table_name} (\\n  {\", \".join(columns)}\\n);'\n",
    "\n",
    "# === 2. Connect to Snowflake ===\n",
    "conn = snowflake.connector.connect(\n",
    "    user='BRIJESH',\n",
    "    password='Temp@115599',\n",
    "    account='agb63276',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database=database,\n",
    "    schema=schema,\n",
    "    role='ACCOUNTADMIN'\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# === 3. Create table dynamically ===\n",
    "cur.execute(ddl)\n",
    "print(f\"✅ Table {table_name} created.\")\n",
    "\n",
    "# === 4. Upload CSV to user stage (not table stage) ===\n",
    "stage_path = f\"@~/{os.path.basename(local_file)}\"  # @~ is user stage\n",
    "cur.execute(f\"PUT file://{local_file} @~ AUTO_COMPRESS=TRUE\")\n",
    "print(\"✅ File uploaded to user stage.\")\n",
    "\n",
    "# === 5. Load data using COPY INTO ===\n",
    "cur.execute(f\"\"\"\n",
    "    COPY INTO {table_name}\n",
    "    FROM {stage_path}\n",
    "    FILE_FORMAT = (TYPE=CSV FIELD_OPTIONALLY_ENCLOSED_BY='\"' SKIP_HEADER=1)\n",
    "    ON_ERROR='CONTINUE'\n",
    "\"\"\")\n",
    "print(f\"✅ Data loaded into table {table_name}.\")\n",
    "\n",
    "# === 6. Cleanup staged file (optional) ===\n",
    "cur.execute(f\"REMOVE {stage_path}\")\n",
    "print(\"✅ Stage cleaned up.\")\n",
    "\n",
    "# === 7. Close connections ===\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
